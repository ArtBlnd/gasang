use crate::aarch64::*;

use std::fmt::{Debug, Display, Formatter, Result as FmtResult};

// AArch64 instruction
#[derive(Clone, Debug, PartialEq, Eq)]
pub enum AArch64Instr {
    AddImm32(ShImm12RnRd),
    AddsImm32(ShImm12RnRd),
    SubImm32(ShImm12RnRd),
    SubsImm32(ShImm12RnRd),
    AddImm64(ShImm12RnRd),
    AddsImm64(ShImm12RnRd),
    SubImm64(ShImm12RnRd),
    SubsImm64(ShImm12RnRd),

    AndImm32(LogicalImm),
    OrrImm32(LogicalImm),
    EorImm32(LogicalImm),
    AndsImm32(LogicalImm),
    AndImm64(LogicalImm),
    OrrImm64(LogicalImm),
    EorImm64(LogicalImm),
    AndsImm64(LogicalImm),

    Addg(AddSubImmWithTags),
    Subg(AddSubImmWithTags),

    Extr32(ExtractImm),
    Extr64(ExtractImm),

    Clrex(Barriers),
    DsbEncoding(Barriers),
    Dmb(Barriers),
    Isb(Barriers),

    Sbfm32(Bitfield),
    Bfm32(Bitfield),
    Ubfm32(Bitfield),
    Sbfm64(Bitfield),
    Bfm64(Bitfield),
    Ubfm64(Bitfield),

    AddShiftedReg32(RmRnRd),
    AddsShiftedReg32(RmRnRd),
    SubShiftedReg32(RmRnRd),
    SubsShiftedReg32(RmRnRd),
    AddShiftedReg64(RmRnRd),
    AddsShiftedReg64(RmRnRd),
    SubShiftedReg64(RmRnRd),
    SubsShiftedReg64(RmRnRd),

    AddExtReg32(AddSubtractExtReg),
    AddsExtReg32(AddSubtractExtReg),
    SubExtReg32(AddSubtractExtReg),
    SubsExtReg32(AddSubtractExtReg),
    AddExtReg64(AddSubtractExtReg),
    AddsExtReg64(AddSubtractExtReg),
    SubExtReg64(AddSubtractExtReg),
    SubsExtReg64(AddSubtractExtReg),

    FmAddSinglePrecision(RmRaRnRd),
    FmSubSinglePrecision(RmRaRnRd),
    FnmAddSinglePrecision(RmRaRnRd),
    FnmSubSinglePrecision(RmRaRnRd),
    FmAddDoublePrecision(RmRaRnRd),
    FmSubDoublePrecision(RmRaRnRd),
    FnmAddDoublePrecision(RmRaRnRd),
    FnmSubDoublePrecision(RmRaRnRd),
    FmAddHalfPrecision(RmRaRnRd),
    FmSubHalfPrecision(RmRaRnRd),
    FnmAddHalfPrecision(RmRaRnRd),
    FnmSubHalfPrecision(RmRaRnRd),

    StrbImm(Imm12RnRt),
    LdrbImm(Imm12RnRt),
    LdrsbImm32(Imm12RnRt),
    LdrsbImm64(Imm12RnRt),
    StrImmSimdFP8(Imm12RnRt),
    LdrImmSimdFP8(Imm12RnRt),
    StrImmSimdFP128(Imm12RnRt),
    LdrImmSimdFP128(Imm12RnRt),
    StrhImm(Imm12RnRt),
    LdrhImm(Imm12RnRt),
    LdrshImm32(Imm12RnRt),
    LdrshImm64(Imm12RnRt),
    StrImmSimdFP16(Imm12RnRt),
    LdrImmSimdFP16(Imm12RnRt),
    StrImm32(Imm12RnRt),
    LdrImm32(Imm12RnRt),
    LdrswImm(Imm12RnRt),
    StrImmSimdFP32(Imm12RnRt),
    LdrImmSimdFP32(Imm12RnRt),
    StrImm64(Imm12RnRt),
    LdrImm64(Imm12RnRt),
    PrfmImm(Imm12RnRt),
    StrImmSimdFP64(Imm12RnRt),
    LdrImmSimdFP64(Imm12RnRt),

    StrbRegExtReg(LoadStoreRegRegOffset),
    StrbRegShiftedReg(LoadStoreRegRegOffset),
    LdrbRegExtReg(LoadStoreRegRegOffset),
    LdrbRegShiftedReg(LoadStoreRegRegOffset),
    LdrsbRegExtReg64(LoadStoreRegRegOffset),
    LdrsbRegShiftedReg64(LoadStoreRegRegOffset),
    LdrsbRegExtReg32(LoadStoreRegRegOffset),
    LdrsbRegShiftedReg32(LoadStoreRegRegOffset),
    StrRegSimdFP(LoadStoreRegRegOffset),
    LdrRegSimdFP(LoadStoreRegRegOffset),
    StrhReg(LoadStoreRegRegOffset),
    LdrhReg(LoadStoreRegRegOffset),
    LdrshReg64(LoadStoreRegRegOffset),
    LdrshReg32(LoadStoreRegRegOffset),
    StrReg32(LoadStoreRegRegOffset),
    LdrReg32(LoadStoreRegRegOffset),
    LdrswReg(LoadStoreRegRegOffset),
    StrReg64(LoadStoreRegRegOffset),
    LdrReg64(LoadStoreRegRegOffset),
    PrfmReg(LoadStoreRegRegOffset),

    Stp32(LoadStoreRegPair),
    Ldp32(LoadStoreRegPair),
    StpSimdFP32(LoadStoreRegPair),
    LdpSimdFP32(LoadStoreRegPair),
    Stgp(LoadStoreRegPair),
    Ldpsw(LoadStoreRegPair),
    StpSimdFP64(LoadStoreRegPair),
    LdpSimdFP64(LoadStoreRegPair),
    Stp64(LoadStoreRegPair),
    Ldp64(LoadStoreRegPair),
    StpSimdFP128(LoadStoreRegPair),
    LdpSimdFP128(LoadStoreRegPair),

    Sturb(Imm12RnRt),
    Ldurb(Imm12RnRt),
    Ldursb64(Imm12RnRt),
    Ldursb32(Imm12RnRt),
    SturSimdFP8(Imm12RnRt),
    LdurSimdFP8(Imm12RnRt),
    SturSimdFP128(Imm12RnRt),
    LdurSimdFP128(Imm12RnRt),
    Sturh(Imm12RnRt),
    Ldurh(Imm12RnRt),
    Ldursh64(Imm12RnRt),
    Ldursh32(Imm12RnRt),
    SturSimdFP16(Imm12RnRt),
    LdurSimdFP16(Imm12RnRt),
    Stur32(Imm12RnRt),
    Ldur32(Imm12RnRt),
    Ldursw(Imm12RnRt),
    SturSimdFP32(Imm12RnRt),
    LdurSimdFP32(Imm12RnRt),
    Stur64(Imm12RnRt),
    Ldur64(Imm12RnRt),
    Prefum(Imm12RnRt),
    SturSimdFP64(Imm12RnRt),
    LdurSimdFP64(Imm12RnRt),

    StpVar32(LoadStoreRegPair),
    LdpVar32(LoadStoreRegPair),
    StpSimdFPVar32(LoadStoreRegPair),
    LdpSimdFPVar32(LoadStoreRegPair),
    StpSimdFPVar64(LoadStoreRegPair),
    LdpSimdFPVar64(LoadStoreRegPair),
    StpVar64(LoadStoreRegPair),
    LdpVar64(LoadStoreRegPair),
    StpSimdFpVar128(LoadStoreRegPair),
    LdpSimdFpVar128(LoadStoreRegPair),

    BImm(Imm26),
    BlImm(Imm26),

    BCond(Imm19Cond),
    BcCond(Imm19Cond),

    Tbz(B5B40Imm14Rt),
    Tbnz(B5B40Imm14Rt),

    Cbz32(CmpAndBranchImm),
    Cbnz32(CmpAndBranchImm),
    Cbz64(CmpAndBranchImm),
    Cbnz64(CmpAndBranchImm),

    MsrReg(SysRegMov),
    Mrs(SysRegMov),

    Csel32(RmCondRnRd),
    Csinc32(RmCondRnRd),
    Csinv32(RmCondRnRd),
    Csneg32(RmCondRnRd),
    Csel64(RmCondRnRd),
    Csinc64(RmCondRnRd),
    Csinv64(RmCondRnRd),
    Csneg64(RmCondRnRd),

    Movn32(Imm16Rd),
    Movz32(Imm16Rd),
    Movk32(Imm16Rd),
    Movn64(Imm16Rd),
    Movz64(Imm16Rd),
    Movk64(Imm16Rd),

    AndShiftedReg32(ShiftRmImm6RnRd),
    BicShiftedReg32(ShiftRmImm6RnRd),
    OrrShiftedReg32(ShiftRmImm6RnRd),
    OrnShiftedReg32(ShiftRmImm6RnRd),
    EorShiftedReg32(ShiftRmImm6RnRd),
    EonShiftedReg32(ShiftRmImm6RnRd),
    AndsShiftedReg32(ShiftRmImm6RnRd),
    BicsShiftedReg32(ShiftRmImm6RnRd),

    AndShiftedReg64(ShiftRmImm6RnRd),
    BicShiftedReg64(ShiftRmImm6RnRd),
    OrrShiftedReg64(ShiftRmImm6RnRd),
    OrnShiftedReg64(ShiftRmImm6RnRd),
    EorShiftedReg64(ShiftRmImm6RnRd),
    EonShiftedReg64(ShiftRmImm6RnRd),
    AndsShiftedReg64(ShiftRmImm6RnRd),
    BicsShiftedReg64(ShiftRmImm6RnRd),

    Madd32(DataProc3Src),
    Msub32(DataProc3Src),
    Madd64(DataProc3Src),
    Msub64(DataProc3Src),
    Smaddl(DataProc3Src),
    Smsubl(DataProc3Src),
    Smulh(DataProc3Src),
    Umaddl(DataProc3Src),
    Umsubl(DataProc3Src),
    Umulh(DataProc3Src),

    UdivVar32(DataProc2Src),
    SdivVar32(DataProc2Src),
    LslvVar32(DataProc2Src),
    LsrvVar32(DataProc2Src),
    AsrvVar32(DataProc2Src),
    RorvVar32(DataProc2Src),
    UdivVar64(DataProc2Src),
    SdivVar64(DataProc2Src),
    LslvVar64(DataProc2Src),
    LsrvVar64(DataProc2Src),
    AsrvVar64(DataProc2Src),
    RorvVar64(DataProc2Src),

    CcmnRegVar32(CondCmpReg),
    CcmpRegVar32(CondCmpReg),
    CcmnRegVar64(CondCmpReg),
    CcmpRegVar64(CondCmpReg),

    RbitVar32(RnRd),
    Rev16Var32(RnRd),
    RevVar32(RnRd),
    ClzVar32(RnRd),
    ClsVar32(RnRd),
    RbitVar64(RnRd),
    Rev16Var64(RnRd),
    Rev32(RnRd),
    RevVar64(RnRd),
    ClzVar64(RnRd),
    ClsVar64(RnRd),

    Br(UncondBranchReg),
    Blr(UncondBranchReg),
    Ret(UncondBranchReg),
    ERet(UncondBranchReg),
    Drps(UncondBranchReg),

    Nop,
    Yield,
    Wfe,
    Wfi,
    Sev,
    Sevl,

    Adr(PcRelAddressing),
    Adrp(PcRelAddressing),

    Svc(ExceptionGen),
    Hvc(ExceptionGen),
    Smc(ExceptionGen),
    Brk(ExceptionGen),
    Hlt(ExceptionGen),
    TCancle(ExceptionGen),
    DcpS1(ExceptionGen),
    DcpS2(ExceptionGen),
    DcpS3(ExceptionGen),

    DupElement(AdvancedSimdCopy),
    DupGeneral(AdvancedSimdCopy),
    Smov(AdvancedSimdCopy),
    Umov(AdvancedSimdCopy),
    InsGeneral(AdvancedSimdCopy),
    InsElement(AdvancedSimdCopy),

    St4MulStructures(AdvSimdLdStMultiStructures),
    St1MulStructures4RegsVar(AdvSimdLdStMultiStructures),
    St3MulStructures(AdvSimdLdStMultiStructures),
    St1MulStructures3RegsVar(AdvSimdLdStMultiStructures),
    St1MulStructures1RegsVar(AdvSimdLdStMultiStructures),
    St2MulStructures(AdvSimdLdStMultiStructures),
    St1MulStructures2RegsVar(AdvSimdLdStMultiStructures),
    Ld4MulStructures(AdvSimdLdStMultiStructures),
    Ld1MulStructures4RegsVar(AdvSimdLdStMultiStructures),
    Ld3MulStructures(AdvSimdLdStMultiStructures),
    Ld1MulStructures3RegsVar(AdvSimdLdStMultiStructures),
    Ld1MulStructures1RegsVar(AdvSimdLdStMultiStructures),
    Ld2MulStructures(AdvSimdLdStMultiStructures),
    Ld1MulStructures2RegsVar(AdvSimdLdStMultiStructures),

    St4MulStructuresRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St1MulStructures4RegRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St3MulStructuresRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St1MulStructures3RegRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St1MulStructures1RegRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St2MulStructuresRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St1MulStructures2RegRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St4MulStructuresImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St1MulStructures4RegImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St3MulStructuresImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St1MulStructures3RegImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St1MulStructures1RegImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St2MulStructuresImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    St1MulStructures2RegImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),

    Ld4MulStructuresRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld1MulStructures4RegRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld3MulStructuresRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld1MulStructures3RegRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld1MulStructures1RegRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld2MulStructuresRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld1MulStructures2RegRegOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld4MulStructuresImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld1MulStructures4RegImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld3MulStructuresImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld1MulStructures3RegImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld1MulStructures1RegImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld2MulStructuresImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    Ld1MulStructures2RegImmOffsetVar(AdvSimdLdStMultiStructuresPostIndexed),
    
    FcvtnsScalarSinglePrecisionTo32(RnRd),
    FcvtnuScalarSinglePrecisionTo32(RnRd),
    ScvtfScalarInt32ToSinglePrecision(RnRd),
    UcvtfScalarInt32ToSinglePrecision(RnRd),
    FcvtasScalarSinglePrecisionTo32(RnRd),
    FcvtauScalarSinglePrecisionTo32(RnRd),
    FmovGeneralSinglePrecisionTo32(RnRd),
    FmovGeneral32ToSinglePrecision(RnRd),
    FcvtpsScalarSinglePrecisionTo32(RnRd),
    FcvtpuScalarSinglePrecisionTo32(RnRd),
    FcvtmsScalarSinglePrecisionTo32(RnRd),
    FcvtmuScalarSinglePrecisionTo32(RnRd),
    FcvtzsScalarIntSinglePrecisionTo32(RnRd),
    FcvtzuScalarIntSinglePrecisionTo32(RnRd),
    FcvtnsScalarDoublePrecisionTo32(RnRd),
    FcvtnuScalarDoublePrecisionTo32(RnRd),
    ScvtfScalarInt32ToDoublePrecision(RnRd),
    UcvtfScalarInt32ToDoublePrecision(RnRd),
    FcvtasScalarDoublePrecisionTo32(RnRd),
    FcvtauScalarDoublePrecisionTo32(RnRd),
    FcvtpsScalarDoublePrecisionTo32(RnRd),
    FcvtpuScalarDoublePrecisionTo32(RnRd),
    FcvtmsScalarDoublePrecisionTo32(RnRd),
    FcvtmuScalarDoublePrecisionTo32(RnRd),
    FcvtzsScalarIntDoublePrecisionTo32(RnRd),
    FcvtzuScalarIntDoublePrecisionTo32(RnRd),
    Fjcvtzs(RnRd),

    FcvtnsScalarSinglePrecisionTo64(RnRd),
    FcvtnuScalarSinglePrecisionTo64(RnRd),
    ScvtfScalarInt64ToSinglePrecision(RnRd),
    UcvtfScalarInt64ToSinglePrecision(RnRd),
    FcvtasScalarSinglePrecisionTo64(RnRd),
    FcvtauScalarSinglePrecisionTo64(RnRd),
    FcvtpsScalarSinglePrecisionTo64(RnRd),
    FcvtpuScalarSinglePrecisionTo64(RnRd),
    FcvtmsScalarSinglePrecisionTo64(RnRd),
    FcvtmuScalarSinglePrecisionTo64(RnRd),
    FcvtzsScalarIntSinglePrecisionTo64(RnRd),
    FcvtzuScalarIntSinglePrecisionTo64(RnRd),

    FcvtnsScalarDoublePrecisionTo64(RnRd),
    FcvtnuScalarDoublePrecisionTo64(RnRd),
    ScvtfScalarInt64ToDoublePrecision(RnRd),
    UcvtfScalarInt64ToDoublePrecision(RnRd),
    FcvtasScalarDoublePrecisionTo64(RnRd),
    FcvtauScalarDoublePrecisionTo64(RnRd),
    FmovGeneralDoublePrecisionTo64(RnRd),
    FmovGeneral64ToDoublePrecision(RnRd),
    FcvtpsScalarDoublePrecisionTo64(RnRd),
    FcvtpuScalarDoublePrecisionTo64(RnRd),
    FcvtmsScalarDoublePrecisionTo64(RnRd),
    FcvtmuScalarDoublePrecisionTo64(RnRd),
    FcvtzsScalarIntDoublePrecisionTo64(RnRd),
    FcvtzuScalarIntDoublePrecisionTo64(RnRd),

    FmovGeneralTopHalfOf128To64(RnRd),
    FmovGeneral64toTopHalfOf128(RnRd),

    Ext(AdvancedSimdExtract),
}
